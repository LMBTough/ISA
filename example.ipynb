{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, inception_v3, googlenet, vgg16, mobilenet_v2\n",
    "from saliency.saliency_zoo import fast_ig, guided_ig, big, agi, ig, ISA, saliencymap, sm, sg, saliencymap, deeplift\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "setup_seed(3407)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True).eval().to(device)\n",
    "sm = nn.Softmax(dim=-1)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "norm_layer = transforms.Normalize(mean, std)\n",
    "sm = nn.Softmax(dim=-1)\n",
    "model = nn.Sequential(norm_layer, model, sm).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = torch.load(\"data/img_batch.pt\") # img_batch.shape = (1000,3,224,224)\n",
    "target_batch = torch.load(\"data/label_batch.pt\") # target_batch.shape = (1000,)\n",
    "batch_size = 128\n",
    "attributions = []\n",
    "for i in tqdm(range(0, len(img_batch), batch_size)):\n",
    "    img = img_batch[i:i+batch_size].to(device)\n",
    "    target = target_batch[i:i+batch_size].to(device)\n",
    "    attributions.append(mfaba_sharp(model, img, target))\n",
    "if attributions[0].shape.__len__() == 3:\n",
    "    attributions = [np.expand_dims(attribution, axis=0) for attribution in attributions]\n",
    "attributions = np.concatenate(attributions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
